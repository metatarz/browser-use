from langchain_openai import ChatOpenAI
from browser_use import Agent, Controller
import asyncio
from dotenv import load_dotenv
from browser_use.browser.browser import Browser, BrowserConfig
from websocket_server import initialize_server, start_server, set_message_handler, send_message
import os

os.environ["ANONYMIZED_TELEMETRY"] = "false"

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini")

browser = Browser(
    config=BrowserConfig(
        cdp_url="ws://localhost:9223",
    )
)
controller = Controller()

# Lock to ensure only one agent runs at a time
agent_lock = asyncio.Lock()

async def handle_websocket_message(message: str):
    """Handle incoming WebSocket messages as tasks for the agent."""
    if agent_lock.locked():
        print(f"⚠️  Agent is busy. Discarding message: {message}")
        return
    async with agent_lock:  # Acquire the lock
        print(f"Received task: {message}")
        agent = Agent(
            task=message,
            llm=llm,
            browser=browser,
            controller=controller,
            save_conversation_path="logs/conversation"
        )
        result = await agent.run()
        print(f"Task result: {result}")
        # Optionally, send the result back to the client
        await send_message(f"Task result: {result}")
        await browser.close()
async def main():
    # Initialize and start WebSocket server
    initialize_server()
    
    # Set the message handler to process tasks
    set_message_handler(handle_websocket_message)
    
    # Start the WebSocket server
    await start_server()
    
    # Keep the server running
    await asyncio.Future()  # Run forever

if __name__ == '__main__':
    asyncio.run(main())
